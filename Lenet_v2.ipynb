{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lenet v2.ipynb",
      "provenance": [],
      "mount_file_id": "1_I5zYBYxyRy2urweBPi4evSpoAvXaVJz",
      "authorship_tag": "ABX9TyMwAziCWPuDeTi6I5E2brYl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfraHossain/Neural-network/blob/main/Lenet_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeSyQyp53JVx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import torchvision\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efpvSu4J3Pai"
      },
      "source": [
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXMHxsTS3QN4",
        "outputId": "26cb4dab-b331-4ae1-bb72-a5f3635c63e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7T1W9IU3QVq"
      },
      "source": [
        "train_dataset_path=\"/content/drive/MyDrive/Dataset/train\"\n",
        "test_dataset_path=\"/content/drive/MyDrive/Dataset/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBeFHZQv3QbD"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "          transforms.Resize((32, 32)),\n",
        "          transforms.ToTensor()\n",
        "          ])\n",
        "\n",
        "train_set = torchvision.datasets.ImageFolder(root = train_dataset_path, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "test_set = torchvision.datasets.ImageFolder(root = test_dataset_path, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
        "\n",
        "train_data_size = len(train_set)\n",
        "test_data_size = len(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L36mLgf03QeP",
        "outputId": "e6fa7799-e6b3-41e5-cacb-33aa71458ad5"
      },
      "source": [
        "training_data = enumerate(trainloader)\n",
        "batch_idx, (images, labels) = next(training_data)\n",
        "print(images.shape) # Size of the image\n",
        "print(labels.shape) # Size of the labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 32, 32])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1TCXNxV3Qg6"
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        \n",
        "        self.convolutional_layer = nn.Sequential(            \n",
        "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
        "            nn.Tanh(),\n",
        "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
        "            nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.linear_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=120, out_features=84),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(in_features=84, out_features=4),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convolutional_layer(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.linear_layer(x)\n",
        "        x = F.softmax(x, dim=1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEqL4NWN3Qjw",
        "outputId": "ba3abb95-7da6-4c10-8a33-f8532ae5026c"
      },
      "source": [
        "model = LeNet5().to(device)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet5(\n",
            "  (convolutional_layer): Sequential(\n",
            "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): Tanh()\n",
            "    (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): Tanh()\n",
            "    (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (7): Tanh()\n",
            "  )\n",
            "  (linear_layer): Sequential(\n",
            "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
            "    (1): Tanh()\n",
            "    (2): Linear(in_features=84, out_features=4, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7UgJ2Ds5O2d"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeXW19HZ5PBR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de07d0e-dee7-4b3d-e0bc-08b6adb265a4"
      },
      "source": [
        "epochs = 30\n",
        "train_loss, val_loss = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "   \n",
        "    total_train_loss = 0\n",
        "    total_val_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    \n",
        "    # training our model\n",
        "    for idx, (image, label) in enumerate(trainloader):\n",
        "\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(image)\n",
        "\n",
        "        loss = criterion(pred, label)\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    total_train_loss = total_train_loss / (idx + 1)\n",
        "    train_loss.append(total_train_loss)\n",
        "    \n",
        "    # validating our model\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    for idx, (image, label) in enumerate(testloader):\n",
        "        image, label = image.to(device), label.to(device)\n",
        "        pred = model(image)\n",
        "        loss = criterion(pred, label)\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        pred = torch.nn.functional.softmax(pred, dim=1)\n",
        "        for i, p in enumerate(pred):\n",
        "            if label[i] == torch.max(p.data, 0)[1]:\n",
        "                total = total + 1\n",
        "\n",
        "    accuracy = total / test_data_size\n",
        "\n",
        "    total_val_loss = total_val_loss / (idx + 1)\n",
        "    val_loss.append(total_val_loss)\n",
        "    print(f\"Epoch: {epoch} | Train Loss: {total_train_loss} | Val Loss: {total_val_loss} | Acc: {accuracy}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Train Loss: 1.1863351279554275 | Val Loss: 1.3556555358190385 | Acc: 0.355\n",
            "Epoch: 1 | Train Loss: 1.079248150316671 | Val Loss: 1.3999658955468073 | Acc: 0.32475\n",
            "Epoch: 2 | Train Loss: 1.0527846632293238 | Val Loss: 1.424151134869409 | Acc: 0.299\n",
            "Epoch: 3 | Train Loss: 1.0355605475437908 | Val Loss: 1.3934074886261472 | Acc: 0.341\n",
            "Epoch: 4 | Train Loss: 1.0235455698860338 | Val Loss: 1.4032640873439728 | Acc: 0.323\n",
            "Epoch: 5 | Train Loss: 1.0060054659843445 | Val Loss: 1.4071075310782781 | Acc: 0.32775\n",
            "Epoch: 6 | Train Loss: 0.9894096710430548 | Val Loss: 1.4108548523887756 | Acc: 0.3185\n",
            "Epoch: 7 | Train Loss: 0.9768014003674443 | Val Loss: 1.429921585416037 | Acc: 0.2985\n",
            "Epoch: 8 | Train Loss: 0.9597595183613201 | Val Loss: 1.3543312152226765 | Acc: 0.37525\n",
            "Epoch: 9 | Train Loss: 0.9420512510945622 | Val Loss: 1.385264553720989 | Acc: 0.34175\n",
            "Epoch: 10 | Train Loss: 0.9298336964826615 | Val Loss: 1.3349658194042386 | Acc: 0.39925\n",
            "Epoch: 11 | Train Loss: 0.915520926824393 | Val Loss: 1.3074113149491569 | Acc: 0.42425\n",
            "Epoch: 12 | Train Loss: 0.9029651564150192 | Val Loss: 1.3346312064973136 | Acc: 0.3995\n",
            "Epoch: 13 | Train Loss: 0.8934989695350963 | Val Loss: 1.302125546667311 | Acc: 0.42975\n",
            "Epoch: 14 | Train Loss: 0.8791231347349124 | Val Loss: 1.3112648365989563 | Acc: 0.4195\n",
            "Epoch: 15 | Train Loss: 0.8705691339108891 | Val Loss: 1.297509651335459 | Acc: 0.43725\n",
            "Epoch: 16 | Train Loss: 0.8633795144458929 | Val Loss: 1.3471010999074058 | Acc: 0.3825\n",
            "Epoch: 17 | Train Loss: 0.8552730416718383 | Val Loss: 1.3411481285852098 | Acc: 0.3875\n",
            "Epoch: 18 | Train Loss: 0.8484363605420049 | Val Loss: 1.2790991957225497 | Acc: 0.44375\n",
            "Epoch: 19 | Train Loss: 0.8444763837150111 | Val Loss: 1.3730149458325098 | Acc: 0.35475\n",
            "Epoch: 20 | Train Loss: 0.8346786529492265 | Val Loss: 1.2916690149004497 | Acc: 0.43775\n",
            "Epoch: 21 | Train Loss: 0.8289245633652416 | Val Loss: 1.2876093217304774 | Acc: 0.44025\n",
            "Epoch: 22 | Train Loss: 0.8235726301281597 | Val Loss: 1.3527197421543182 | Acc: 0.37675\n",
            "Epoch: 23 | Train Loss: 0.8170811101651421 | Val Loss: 1.2626664108700223 | Acc: 0.4705\n",
            "Epoch: 24 | Train Loss: 0.8150068249184483 | Val Loss: 1.2516375269208635 | Acc: 0.48375\n",
            "Epoch: 25 | Train Loss: 0.8134674523204279 | Val Loss: 1.2756573264561002 | Acc: 0.4565\n",
            "Epoch: 26 | Train Loss: 0.8090604218050313 | Val Loss: 1.26690417622763 | Acc: 0.466\n",
            "Epoch: 27 | Train Loss: 0.8046447375711923 | Val Loss: 1.2687545276823498 | Acc: 0.45925\n",
            "Epoch: 28 | Train Loss: 0.8012844807804583 | Val Loss: 1.2818756027827187 | Acc: 0.4405\n",
            "Epoch: 29 | Train Loss: 0.796429879749164 | Val Loss: 1.2743774368649436 | Acc: 0.45975\n"
          ]
        }
      ]
    }
  ]
}